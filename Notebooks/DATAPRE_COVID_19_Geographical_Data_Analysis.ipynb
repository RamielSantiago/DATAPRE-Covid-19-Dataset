{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DATAPRE COVID-19 Data Analysis Project",
      "provenance": [],
      "collapsed_sections": [
        "yqG4trwhbfx7",
        "Mi-ZQHq6S-mq",
        "mlDDL9Lcoj3O",
        "whVxHPSOwJjw",
        "LFAaQAmr_T1I",
        "ALtib7LH_m19",
        "xUf0kAGUd4j3",
        "w1bAx9AJ5pwS",
        "-AQjFdqcKBeC",
        "IcfHDAWHMy4r",
        "t9gz6j8OixUN",
        "-wNghB4Gi0q1"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fnV1XL6cSgui"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mounting Google Drive storage to load required datasets\n",
        "\n",
        "In order to read the required datasets for this analysis, `/content/drive` must be mounted using `drive.mount` into the notebook using the cell below."
      ],
      "metadata": {
        "id": "yqG4trwhbfx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive storage to use dataset in the notebook\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "W7ShfeLPbqSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COVID-19 Dataset"
      ],
      "metadata": {
        "id": "Mi-ZQHq6S-mq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The datasets for this analysis were retrieved from the Philippine Department of Health's COVID-19 Data Drop. A number of datasets can be found from the website, which includes quarantine facility data from the entire Philippines. \n",
        "\n",
        "For this analysis, we are interested in the recorded information by the DOH regarding the cases of COVID-19, labelled as follows:\n",
        "\n",
        "DOH COVID Data Drop_ 20220409 - 04 Case Information_batch_0<br>\n",
        "DOH COVID Data Drop_ 20220409 - 04 Case Information_batch_1<br>\n",
        "DOH COVID Data Drop_ 20220409 - 04 Case Information_batch_2<br>\n",
        "DOH COVID Data Drop_ 20220409 - 04 Case Information_batch_3<br>\n",
        "\n",
        "The link to the DOH COVID-19 Data Drop can be found [here](https://drive.google.com/drive/folders/15AbIeK20aPzfta24p-9fUSDcHu-uCw5v)"
      ],
      "metadata": {
        "id": "F-lOxs7Gmk02"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading and processing the data"
      ],
      "metadata": {
        "id": "mlDDL9Lcoj3O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The four datasets can be retrieved individually as follows:"
      ],
      "metadata": {
        "id": "LzrLX_HPprsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# READING THE DATA\n",
        "data_1 = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/DOH COVID Data Drop_ 20220618 - 04 Case Information_batch_0.csv')\n",
        "data_2 = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/DOH COVID Data Drop_ 20220618 - 04 Case Information_batch_1.csv')\n",
        "data_3 = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/DOH COVID Data Drop_ 20220618 - 04 Case Information_batch_2.csv')\n",
        "data_4 = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/DOH COVID Data Drop_ 20220618 - 04 Case Information_batch_3.csv')\n",
        "\n",
        "print('Successfully loaded the data')"
      ],
      "metadata": {
        "id": "Iy7buH69p054"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It would be ideal to combine all the datasets to a single `DataFrame`, hence performing `concat` would allow us to combine all of the datasets. However, the shapes of the datasets must first be verified to assure that all of the datasets have the same variables."
      ],
      "metadata": {
        "id": "GOZzwBvfqirq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Data 1 shape:', data_1.shape)\n",
        "print('Data 2 shape:', data_2.shape)\n",
        "print('Data 3 shape:', data_3.shape)\n",
        "print('Data 4 shape:', data_4.shape)"
      ],
      "metadata": {
        "id": "4wA2XuqvsIbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also manually inspect the columns of the dataset by printing them out using `df.columns`"
      ],
      "metadata": {
        "id": "cMM7eY9LuagU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_1.columns"
      ],
      "metadata": {
        "id": "uGD9hUBwvFrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2.columns"
      ],
      "metadata": {
        "id": "viRgunWavNAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_3.columns"
      ],
      "metadata": {
        "id": "pB4vlY-TvY--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_4.columns"
      ],
      "metadata": {
        "id": "7aQzFzb2vbD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upon inspection, we have now verified that the columns are the same per dataset. The said datasets can now be safely combined using `concat`"
      ],
      "metadata": {
        "id": "TgJvZONuvcBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doh_data = pd.concat([data_1, data_2, data_3, data_4])\n",
        "doh_data.head()"
      ],
      "metadata": {
        "id": "OdyAhhcMv58X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Dictionary\n",
        "\n",
        "As taken from the DataDrop Field Metadata, the following features can be described as: \n",
        "\n",
        "| Variable          | Definition                                |\n",
        "| ---------         | ----------------------------------------  |\n",
        "| Casecode          | Random code assigned for labelling cases  |\n",
        "| Age               | Age                                       |\n",
        "| AgeGroup          | Five-year age group                       |\n",
        "| Sex               | Sex                                       |\n",
        "| DateSpecimen      | Date when specimen was collected          |\n",
        "| DateResultRelease | Date of release result                    |\n",
        "| DateRepConf       | Date publicly announced as confirmed case |\n",
        "| DateDied          | Date died                                 |\n",
        "| DateRecover       | Date Recovered                            |\n",
        "| RemovalType       | Type of removal (recovery or death)       |\n",
        "| Admitted          | Binary variable indicating that the patient has been taken to the hospital |\n",
        "| RegionRes         | Region of residence |\n",
        "| ProvRes           | Province of residence |\n",
        "| CityMunRes        | City of residence |\n",
        "| CityregPSGC      | Philippine Standard Geographic Code of regcipality or City of residence |\n",
        "| BarangayRes       | Barangay of residence |\n",
        "| BarangayPSGC     | Philippine Standard Geographic Code of regcipality or City of residence |\n",
        "| HealthStatus      | Known current health status of patient (asymptomatic, mild, severe, critical, died, recovered) |\n",
        "| Quarantined       | Identifies if the patient has ever been home quarantined |\n",
        "| DateOnset         | Date of onset symptoms |\n",
        "| Pregnanttab       | If the patient was pregnant at any point during the COVID-19 condition |"
      ],
      "metadata": {
        "id": "whVxHPSOwJjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic information regarding the data can also be retrieved such as its descriptive statistics on applicable variables using `describe`"
      ],
      "metadata": {
        "id": "_IpWQfEzwf5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doh_data.describe()"
      ],
      "metadata": {
        "id": "HCTae6_49T0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We would also be interested in identifying the different data type that is present on each variable using `dtypes`"
      ],
      "metadata": {
        "id": "2dTAcDLZ9WaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doh_data.dtypes"
      ],
      "metadata": {
        "id": "Mi-4Up0-9nSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Wrangling"
      ],
      "metadata": {
        "id": "LFAaQAmr_T1I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As with any dataset, it would be ideal to identify errors in the values caused by faults in encoding the data. The following section aims to seek these kinds of errors in the data."
      ],
      "metadata": {
        "id": "4q_QUptJ_4Kh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Duplicates and Null Values"
      ],
      "metadata": {
        "id": "ALtib7LH_m19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doh_data.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-GUw16z_2gg",
        "outputId": "2a78aeb9-82f3-486d-8fd5-8414303ad29e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CaseCode                   1\n",
              "Age                     2906\n",
              "AgeGroup                2906\n",
              "Sex                       43\n",
              "DateSpecimen          829920\n",
              "DateResultRelease     831379\n",
              "DateRepConf                0\n",
              "DateDied             3635482\n",
              "DateRecover          3032685\n",
              "RemovalType             4176\n",
              "Admitted             2299493\n",
              "RegionRes               3359\n",
              "ProvRes                49881\n",
              "CityMunRes             59045\n",
              "CityMuniPSGC           58931\n",
              "BarangayRes           316142\n",
              "BarangayPSGC          316000\n",
              "HealthStatus               0\n",
              "Quarantined              146\n",
              "DateOnset            2327362\n",
              "Pregnanttab          1810717\n",
              "ValidationStatus      513669\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As indicated by the cell above, most of the variables have a missing value pertaining to the case's information. However, it would be prudent to refrain from dropping these cases given the context of the dataset. Certain relationships between variables could thus be explored which makes use of the available values per variable."
      ],
      "metadata": {
        "id": "CG-7kMVJAgv6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Duplicated data, however, can be safely dropped as these cases wold affect the accuracy of certain statistical information regarding the dataset. "
      ],
      "metadata": {
        "id": "RUzpANPjLX-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doh_data.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGhwIjRhKSBM",
        "outputId": "9cbe1d31-a578-4ffd-ced1-36a609745be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the returned value for the number of duplicated rows in the dataset is zero, we can assume that there are no redundant information regarding the dataset. If we tried to check on the duplicated values for the `CaseCode`, however, a certain value will be returned by the `duplicated()` function. We can disregard this value since it was stated by the DOH that these values are not unique, such that they are randomly assigned to the patient's case."
      ],
      "metadata": {
        "id": "qHHy2xzAKzYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doh_data.duplicated(subset = ['CaseCode']).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvT7PUCNN0wx",
        "outputId": "86be4b57-1cf4-4cd4-ebf9-fcc78b0cfb8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35595"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Geographical Data Analysis"
      ],
      "metadata": {
        "id": "KiRuBFrNsXLF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we have identified that certain regions and cities in the country are more likely to have a greater number of cases compared to others, it would be helpful to create heatmaps to identify the COVID hotspots in the country."
      ],
      "metadata": {
        "id": "OFiMkj6X_teB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install geopandas"
      ],
      "metadata": {
        "id": "e48oHmxrAQzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the provided PSGC column in the `doh_data` dataset, we can pinpoint the geographical location of the cases in the country to create a heatmap. However, further datasets containing the latitude and longitude of a certain PSGC code must be collected. The PSGC shape files were provided by **altcoder** which was placed in the data folder for this analysis.\n",
        "\n",
        "Philippines PSGC Administrative Boundaries Shapefiles: https://github.com/altcoder/philippines-psgc-shapefiles"
      ],
      "metadata": {
        "id": "IwugKMt-AkNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd"
      ],
      "metadata": {
        "id": "uO6GnMiYncFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accessing and Reading the datasets"
      ],
      "metadata": {
        "id": "IcfHDAWHMy4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# READING THE SHAPE DATASETS IN CSV FORMAT\n",
        "baran_data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/Shape Files/Barangays.csv')\n",
        "baran_data.columns"
      ],
      "metadata": {
        "id": "PdKjMr7mMD-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# READING THE SHAPE DATASETS IN CSV FORMAT\n",
        "baran_datashape = gpd.read_file('/content/drive/My Drive/Colab Notebooks/data/Shape Files/BarangaysMin/BarangaysMin.shp')\n",
        "baran_datashape.head()"
      ],
      "metadata": {
        "id": "kc73eQPtiJLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doh_data.columns"
      ],
      "metadata": {
        "id": "FBykJNsXfI0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doh_data[['CityMuniPSGC', 'BarangayPSGC']]"
      ],
      "metadata": {
        "id": "i5NRf37mfKvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of Missing Municipal PSGC Data: ', doh_data['CityMuniPSGC'].isna().sum())\n",
        "print('Number of Missing Barangay PSGC Data: ', doh_data['BarangayPSGC'].isna().sum())"
      ],
      "metadata": {
        "id": "lsSrQsWnf5P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since there is a significant number of null values for the barangay and municipal columns for each recorded observations, it would be ideal not to drop these rows. A separate observation can be implemented for these values regarding their geographical data. In preparation for this, the scope of the exploration in this part will be limited to a single region."
      ],
      "metadata": {
        "id": "OlzLhUYtfwNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Narrowing the Scope of our exploration\n",
        "\n",
        "To narrow the scope of the DataFrame to what is needed for this part of the Exploratory Data Analysis, a new DataFrame object will be created based on the filtering done to baran_datashape limite the data to only ones from the NCR Region. This new DataFrame will be called NCR_datashape."
      ],
      "metadata": {
        "id": "c30w5I8BNAok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Narrow dataframe scope to the NCR Region\n",
        "NCR_datashape = baran_datashape[baran_datashape['ADM1_EN'] == 'National Capital Region']\n",
        "NCR_datashape = NCR_datashape.rename(columns = {'ADM4_EN' : 'Barangay', 'ADM4_PCODE' : 'BarangayPSGC', 'ADM3_EN' : 'city', 'ADM3_PCODE' : 'city_psgc'})\n",
        "NCR_datashape.sort_values(by='Barangay', ascending=True)\n",
        "NCR_datashape.head()"
      ],
      "metadata": {
        "id": "Ukn7oC3lNP01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, the same process will be done to the data on the COVID-19 cases, with only select columns to be used later. This new DatFrame will be called NCR_case_data"
      ],
      "metadata": {
        "id": "RtlMCCjaaNf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NCR_case_data = doh_data[doh_data['ProvRes'] == 'NCR']\n",
        "NCR_case_data = NCR_case_data[['CaseCode', 'DateRepConf', 'DateDied', 'DateRecover', 'CityMunRes', 'CityMuniPSGC', 'BarangayRes', 'BarangayPSGC', 'HealthStatus']]\n",
        "NCR_case_data.head()"
      ],
      "metadata": {
        "id": "2QAazA2lO6rY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After narrowing the scope to just the NCR region, a heat map will be created showing the prevalence of COVID-19 in a the cities/municipalities of the region."
      ],
      "metadata": {
        "id": "_9kwLwc1RsU5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Cleaning and Processing for plotting the HeatMap\n",
        "\n",
        "To prepare for creating the HeatMap, the data will need to be processed to remove any further unnecessary data and create a final DataFrame object to be used as data to plot the HeatMap."
      ],
      "metadata": {
        "id": "KiyplK6eNMe9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, a new column of 1's will be appended to the NCR_case_data DataFrame\n"
      ],
      "metadata": {
        "id": "6gOKndVAbNl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NCR_case_data['CaseCode_n'] = 1\n",
        "NCR_case_data.head()"
      ],
      "metadata": {
        "id": "ZKq7Qn--VBl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, a new DataFrame containing the Baranagy PSGC code, Barangay Number, and total number of cases per Barangay (Case_counts), called NCR_case_test will be created from NCR_case_data."
      ],
      "metadata": {
        "id": "AuazpIJXbVQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NCR_case_test = NCR_case_data.groupby(['BarangayPSGC', 'BarangayRes'], as_index = True)['CaseCode_n'].sum()\n",
        "NCR_case_test = NCR_case_test.reset_index(name = 'Case_Counts')\n",
        "NCR_case_test.head()"
      ],
      "metadata": {
        "id": "9O7O9zkg49Rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, another DataFrame containing the geographical location data (Coordinates, Perimeter, and Area) will be created using the BarangayPSGC and each grouped with an instance of Coordinates, Perimeter, and Area of the Barangay the PSGC code refers to."
      ],
      "metadata": {
        "id": "Y8GBiu4UcAYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "case_geometry = pd.DataFrame(columns = ['geometry'])\n",
        "i = 0\n",
        "for x in NCR_case_test['BarangayPSGC']:\n",
        "  for y, z, a, b in zip(NCR_datashape['BarangayPSGC'], NCR_datashape['geometry'], NCR_datashape['PERIMETER'], NCR_datashape['AREA']):\n",
        "    if x == y:\n",
        "      case_geometry = case_geometry.append({'BarangayPSGC' : x,'geometry' : z, 'PERIMETER' : a, 'AREA' : b}, ignore_index = True)\n",
        "print(case_geometry.columns);\n",
        "print(case_geometry.shape)"
      ],
      "metadata": {
        "id": "2mvqfExW6sv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "case_geometry = case_geometry.rename(columns = {'ADM4_PCODE' : 'BarangayPSGC'})\n",
        "case_geometry.head()"
      ],
      "metadata": {
        "id": "qPJTc8p0-q4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, the two DataFrames that were created earlier are merged into a third, final DataFrame for use in the plotting of the heatmap."
      ],
      "metadata": {
        "id": "rQTWQS5WcuP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_case_test = NCR_case_test.merge(case_geometry, how = 'inner', on = 'BarangayPSGC')\n",
        "final_case_test.head()"
      ],
      "metadata": {
        "id": "5EGsQfjc-5Mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting the HeatMap\n",
        "\n",
        "Finally, this last part is for plotting the heatmap. It begins with merging the final_case_test DataFrame with the NCR_datashape Dataframe, which means the data on the Baranagays and the number of cases per Barangay will be assigned is geographical location and coordinates based on the Barangay PSGC code assigned to it."
      ],
      "metadata": {
        "id": "3eM8jS4JNUkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Case_counts = NCR_datashape.merge(final_case_test, on = 'BarangayPSGC')\n",
        "Case_counts = Case_counts.drop(columns = ['fid',\t'cat',\t'cat__1',\t'cat_', 'ADM1_PCODE',\t'ADM2_PCODE',\t'ADM2_EN',\t'ADM1_EN',\t'ADM_ID',\t'UPDATED', 'geometry_y', 'PERIMETER_y', 'AREA_y', 'BarangayRes'])\n",
        "Case_counts = Case_counts.rename(columns = {'geometry_x' : 'geometry', 'PERIMETER_x' : 'PERIMETER', 'AREA_x' : 'AREA'})\n",
        "print(Case_counts.shape)\n",
        "Case_counts.head()"
      ],
      "metadata": {
        "id": "bON4fkNxETE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, it is time to convert our Pandas Dataframe 'Case_counts' to a GeoPandas GeoDataframe to plot our heatmap."
      ],
      "metadata": {
        "id": "5yXv9NwYMIS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Case_counts = gpd.GeoDataFrame(Case_counts)\n",
        "Case_counts.head()"
      ],
      "metadata": {
        "id": "anZ6h2YZKyyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, it's time to create the heatmap. The structure, appearance, and the values in the heatmap is dependent on the values in the GeoDataFrame used in plotting the heatmap, such as the column 'geometry', which is used to plot each barangay and the 'Case_counts' column to determine how dark each part is compared to the rest of the heatmap. The darker the color, the higher the value for that specifica part, which for this dataset means more cases."
      ],
      "metadata": {
        "id": "8zgKizsoWnsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize = (20, 30))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "Case_counts.plot(ax = ax, figsize = (20, 30), cmap=plt.cm.YlOrBr, legend = True, edgecolor = 'black', column = 'Case_Counts')"
      ],
      "metadata": {
        "id": "4bGNCJsDLShJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Dataset"
      ],
      "metadata": {
        "id": "2JwFz8fEUres"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Creation and Export to CSV file format"
      ],
      "metadata": {
        "id": "H04bgaEGjBgb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cases Per Region\n"
      ],
      "metadata": {
        "id": "t9gz6j8OixUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "TM-gepiGhn0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doh_data[\"RegionRes\"].fillna(\"None Stated\", inplace=True)\n",
        "doh_data[\"CityMunRes\"].fillna(\"None Stated\", inplace=True)\n",
        "regionList = doh_data[\"RegionRes\"].unique()\n",
        "print(regionList)\n",
        "print(regionList.shape)"
      ],
      "metadata": {
        "id": "lq7Z2oeqU566"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(19):\n",
        "    cases_per_region = doh_data.loc[doh_data['RegionRes'] == regionList[i]]\n",
        "    filename = regionList[i] + \".csv\"\n",
        "    csvFile = cases_per_region.to_csv(filename)\n",
        "    files.download(filename)"
      ],
      "metadata": {
        "id": "YOWAmEVGZSiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cases per Municipality in NCR"
      ],
      "metadata": {
        "id": "-wNghB4Gi0q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rValues = doh_data.loc[doh_data['RegionRes'] == 'NCR']\n",
        "cityList = rValues[\"CityMunRes\"].unique()\n",
        "print(cityList)\n",
        "print(cityList.shape)"
      ],
      "metadata": {
        "id": "qDkk5JBIi5mD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(18):\n",
        "  cases_per_municipality = rValues.loc[rValues[\"CityMunRes\"] == cityList[i]]\n",
        "  filename = cityList[i] + \".csv\"\n",
        "  csvFile = cases_per_municipality.to_csv(filename)\n",
        "  files.download(filename)"
      ],
      "metadata": {
        "id": "vSq8iOnen6MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization"
      ],
      "metadata": {
        "id": "Oixoc2hyphEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Regional Heatmap of the Philippines"
      ],
      "metadata": {
        "id": "L-z-OMFv5MFJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Accessing Data"
      ],
      "metadata": {
        "id": "cH1P2xce5MFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg_datashape = gpd.read_file('/content/drive/My Drive/Colab Notebooks/data/Shape Files/Region/Regions.shp')\n",
        "reg_datashape.head()"
      ],
      "metadata": {
        "id": "k_h3YvWs5MFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Cleaning and Processing Data"
      ],
      "metadata": {
        "id": "HmPWDdI45MFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shapeRegList = reg_datashape['ADM1_EN'].unique()\n",
        "sortShapeList = sorted(shapeRegList)\n",
        "sortShapeList"
      ],
      "metadata": {
        "id": "x9bC6Z9T-mZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regional_case_data = doh_data[['CaseCode', 'DateRepConf', 'DateDied', 'DateRecover', 'RegionRes', 'HealthStatus']]\n",
        "newRegList = regional_case_data['RegionRes'].unique()\n",
        "sortRegList = sorted(newRegList)\n",
        "sortRegList"
      ],
      "metadata": {
        "id": "dVRBBHx17bYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sortRegList.remove('None Stated')\n",
        "sortRegList.remove('ROF')\n",
        "for i in range(17):\n",
        "  regional_case_data.replace(sortRegList[i], sortShapeList[i],inplace=True)\n",
        "regional_case_data['RegionRes'].unique()"
      ],
      "metadata": {
        "id": "FENj8LG_-fG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regional_case_data['CaseCode_n'] = 1\n",
        "regional_case_data.head()"
      ],
      "metadata": {
        "id": "LsFjMx7d5MFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "region_case_test = regional_case_data.groupby(['RegionRes'], as_index = True)['CaseCode_n'].sum()\n",
        "region_case_test = region_case_test.reset_index(name = 'Case_Counts')\n",
        "region_case_test = region_case_test.rename(columns = {'RegionRes' : 'ADM1_EN'})\n",
        "region_case_test.head()"
      ],
      "metadata": {
        "id": "UojzWWHY5MFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regional_geometry = pd.DataFrame(columns = ['geometry'])\n",
        "i = 0\n",
        "for x in region_case_test['ADM1_EN']:\n",
        "  for y, z, a, b in zip(reg_datashape['ADM1_EN'], reg_datashape['geometry'], reg_datashape['PERIMETER'], reg_datashape['AREA']):\n",
        "    if x == y:\n",
        "      regional_geometry = regional_geometry.append({'ADM1_EN' : x,'geometry' : z, 'PERIMETER' : a, 'AREA' : b}, ignore_index = True)\n",
        "regional_geometry.head()"
      ],
      "metadata": {
        "id": "Pir-b4sk5MFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_regcase_test = region_case_test.merge(regional_geometry, how = 'inner', on = 'ADM1_EN')\n",
        "final_regcase_test.head()"
      ],
      "metadata": {
        "id": "8Z-Bzg8p5MFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Plotting the Heat Map"
      ],
      "metadata": {
        "id": "amqZMrFg5MFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RegCase_counts = reg_datashape.merge(final_regcase_test, on = 'ADM1_EN')\n",
        "RegCase_counts = RegCase_counts.drop(columns = ['ADM_ID',\t'UPDATED', 'geometry_y', 'PERIMETER_y', 'AREA_y'])\n",
        "RegCase_counts = RegCase_counts.rename(columns = {'geometry_x' : 'geometry', 'PERIMETER_x' : 'PERIMETER', 'AREA_x' : 'AREA', 'ADM1_EN' : 'Region', 'ADM1_PCODE' : 'RegionPSGC'})"
      ],
      "metadata": {
        "id": "FMFWWV0g5MFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RegCase_counts = gpd.GeoDataFrame(RegCase_counts)"
      ],
      "metadata": {
        "id": "9fdnLn0PFLUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize = (20, 30))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "RegCase_counts.plot(ax = ax, figsize = (20, 30), cmap=plt.cm.YlOrBr, legend = True, edgecolor = 'black', column = 'Case_Counts')"
      ],
      "metadata": {
        "id": "wm7m7bOEFDPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Municipal Heatmap of NCR"
      ],
      "metadata": {
        "id": "-7vjvmkip0Mi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Accessing Data"
      ],
      "metadata": {
        "id": "-pK88MRIxLuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "muni_datashape = gpd.read_file('/content/drive/My Drive/Colab Notebooks/data/Shape Files/MunicipalitiesManilaMergedMin/MunicipalitiesManilaMergedMin.shp')\n",
        "muni_datashape.head()"
      ],
      "metadata": {
        "id": "2o7cMgthqs2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Narrowing the Scope"
      ],
      "metadata": {
        "id": "tm_qDtnXxQCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NCR_muni_datashape = muni_datashape[muni_datashape['ADM1_EN'] == 'National Capital Region']\n",
        "NCR_muni_datashape = NCR_muni_datashape.rename(columns = {'ADM4_EN' : 'Barangay', 'ADM4_PCODE' : 'BarangayPSGC', 'ADM3_EN' : 'city', 'ADM3_PCODE' : 'city_psgc'})\n",
        "NCR_muni_datashape.sort_values(by='city', ascending=True)\n",
        "NCR_muni_datashape.head()"
      ],
      "metadata": {
        "id": "EOdYR5karSEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NCR_municase_data = doh_data[doh_data['RegionRes'] == 'NCR']\n",
        "NCR_municase_data = NCR_municase_data[['CaseCode', 'DateRepConf', 'DateDied', 'DateRecover', 'CityMunRes', 'CityMuniPSGC', 'BarangayRes', 'BarangayPSGC', 'HealthStatus']]\n",
        "NCR_municase_data.head()"
      ],
      "metadata": {
        "id": "1OxgSEdPrqyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Cleaning and Processing Data"
      ],
      "metadata": {
        "id": "YRrKaGV8xT74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NCR_municase_data['CaseCode_n'] = 1\n",
        "NCR_municase_data.head()"
      ],
      "metadata": {
        "id": "143m3WYAsA0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NCR_municase_test = NCR_municase_data.groupby(['CityMuniPSGC', 'CityMunRes'], as_index = True)['CaseCode_n'].sum()\n",
        "NCR_municase_test = NCR_municase_test.reset_index(name = 'Case_Counts')\n",
        "NCR_municase_test = NCR_municase_test.rename(columns = {'CityMuniPSGC' : 'city_psgc', 'CityMunRes' : 'city'})\n",
        "NCR_municase_test.head()"
      ],
      "metadata": {
        "id": "xPjJ5_mbsjtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "municase_geometry = pd.DataFrame(columns = ['geometry'])\n",
        "i = 0\n",
        "for x in NCR_municase_test['city_psgc']:\n",
        "  for y, z, a, b in zip(NCR_muni_datashape['city_psgc'], NCR_muni_datashape['geometry'], NCR_muni_datashape['PERIMETER'], NCR_muni_datashape['AREA']):\n",
        "    if x == y:\n",
        "      municase_geometry = municase_geometry.append({'city_psgc' : x,'geometry' : z, 'PERIMETER' : a, 'AREA' : b}, ignore_index = True)\n",
        "municase_geometry.head()"
      ],
      "metadata": {
        "id": "uxzrV6D7swH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_municase_test = NCR_municase_test.merge(municase_geometry, how = 'inner', on = 'city_psgc')\n",
        "final_municase_test.head()"
      ],
      "metadata": {
        "id": "U1icqzA-uUK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Plotting the Heat Map"
      ],
      "metadata": {
        "id": "D1U7e0IixYge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MuniCase_counts = NCR_muni_datashape.merge(final_municase_test, on = 'city_psgc')\n",
        "MuniCase_counts = MuniCase_counts.drop(columns = ['fid',\t'cat',\t'cat__1',\t'cat_', 'ADM1_PCODE',\t'ADM2_PCODE',\t'ADM2_EN',\t'ADM1_EN',\t'ADM_ID',\t'UPDATED', 'geometry_y', 'PERIMETER_y', 'AREA_y', 'city_y'])\n",
        "MuniCase_counts = MuniCase_counts.rename(columns = {'geometry_x' : 'geometry', 'PERIMETER_x' : 'PERIMETER', 'AREA_x' : 'AREA', 'city_x' : 'City'})\n",
        "print(MuniCase_counts.shape)\n",
        "MuniCase_counts.head()"
      ],
      "metadata": {
        "id": "haGVQuCFwKfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MuniCase_counts = gpd.GeoDataFrame(MuniCase_counts)\n",
        "MuniCase_counts.head()"
      ],
      "metadata": {
        "id": "f9PSnMkaFnci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize = (20, 30))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "MuniCase_counts.plot(ax = ax, figsize = (20, 30), cmap=plt.cm.YlOrBr, legend = True, edgecolor = 'black', column = 'Case_Counts')"
      ],
      "metadata": {
        "id": "xX9DyS_lFHVm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}